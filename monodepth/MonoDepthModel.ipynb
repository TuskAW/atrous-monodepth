{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(torch.nn.Module):\n",
    "    def __init__(self,D_in,D_out, k):\n",
    "        super(conv_block, self).__init__() \n",
    "        p = np.floor((k - 1) / 2).astype(np.int32)\n",
    "        self.conv_layer = torch.nn.Conv2d(in_channels= D_in, out_channels= D_out, kernel_size = k ,stride = 2, padding = p) \n",
    "        self.conv_layerb = torch.nn.Conv2d(in_channels= D_out, out_channels= D_out, kernel_size = k ,stride = 1, padding = p)\n",
    "        self.normalize = torch.nn.BatchNorm2d(D_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.conv_layer(x)) \n",
    "        x = self.normalize(x)\n",
    "        x = F.elu(self.conv_layerb(x))\n",
    "        x = self.normalize(x)\n",
    "        return x \n",
    "\n",
    "class upconv(torch.nn.Module):\n",
    "    def __init__(self,D_in,D_out,k, scale):\n",
    "        super(upconv, self).__init__()\n",
    "        self.scale = scale\n",
    "        p = np.floor((k - 1) / 2).astype(np.int32)\n",
    "        self.conv = torch.nn.Conv2d(in_channels= D_in, out_channels= D_out, kernel_size = k ,stride = 1, padding = p)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.nn.functional.interpolate(x, scale_factor=self.scale, mode='bilinear', align_corners=True)\n",
    "        x = self.conv(x)\n",
    "        return torch.nn.functional.elu(x)\n",
    "    \n",
    "class iconv(torch.nn.Module): \n",
    "    def __init__(self, D_in, D_out, k):\n",
    "        super(iconv, self).__init__()\n",
    "        p = np.floor((k - 1) / 2).astype(np.int32)\n",
    "        self.conv = torch.nn.Conv2d(in_channels= D_in, out_channels= D_out, kernel_size = k ,stride = 1, padding = p)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return torch.nn.functional.elu(x)    \n",
    "    \n",
    "class disp(torch.nn.Module):\n",
    "    def __init__ (self, D_in, D_out, k, scale):\n",
    "        super(disp, self).__init__()\n",
    "        p = 1 \n",
    "        self.conv =  torch.nn.Conv2d(in_channels= D_in, out_channels= D_out, kernel_size = k ,stride = 1, padding = p)\n",
    "        self.normalize = torch.nn.BatchNorm2d(2)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.normalize(x)\n",
    "        return 0.3 * self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonoDepthModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MonoDepthModel, self).__init__()\n",
    "        \n",
    "        #specifiy NN architecture\n",
    "        \n",
    "        #encoder \n",
    "        self.conv1 = conv_block(D_in=3,D_out=32,k=7)    # h,w /2 \n",
    "        self.conv2 = conv_block(D_in=32,D_out=64,k=5)   # h,w /4 \n",
    "        self.conv3 = conv_block(D_in=64,D_out=128,k=3)  # h,w /8\n",
    "        self.conv4 = conv_block(D_in=128,D_out=256,k=3) # h,w /16\n",
    "        self.conv5 = conv_block(D_in=256,D_out=512,k=3) # h,w /32\n",
    "        self.conv6 = conv_block(D_in=512,D_out=512,k=3) # h,w /64\n",
    "        self.conv7 = conv_block(D_in=512,D_out=512,k=3) # h,w /128 \n",
    "        #Decoder\n",
    "        self.upconv7 = upconv(D_in = 512, D_out = 512, k = 3, scale = 2) #h,w / 64\n",
    "        self.iconv7 = iconv(D_in = 1024, D_out = 512, k = 3)\n",
    "        self.upconv6 = upconv(D_in = 512, D_out = 512, k = 3, scale = 2) #h,w / 32\n",
    "        self.iconv6 = iconv(D_in = 1024, D_out = 512, k = 3)\n",
    "        self.upconv5 = upconv(D_in = 512, D_out = 256, k = 3, scale = 2) #h,w / 16\n",
    "        self.iconv5 = iconv(D_in = 512, D_out = 256, k = 3)\n",
    "        #-------------------------------------------------------------#\n",
    "        self.upconv4 = upconv(D_in = 256, D_out = 128, k = 3, scale = 2) #h,w / 8\n",
    "        self.iconv4 = iconv(D_in = 256, D_out = 128, k = 3) #WRONG IN THE PAPER?\n",
    "        self.disp4 = disp(D_in = 128, D_out = 2, k = 3, scale = 2)\n",
    "        #-------------------------------------------------------------#\n",
    "        self.upconv3 = upconv(D_in = 128, D_out = 64, k = 3, scale = 2) #h,w / 4\n",
    "        self.iconv3 = iconv(D_in = 130, D_out = 64, k = 3)   #64+64+2\n",
    "        self.disp3 = disp(D_in = 64, D_out = 2, k = 3, scale = 2)\n",
    "        #-------------------------------------------------------------#\n",
    "        self.upconv2 = upconv(D_in = 64, D_out = 32, k = 3, scale = 2 ) #h,w / 2\n",
    "        self.iconv2 = iconv(D_in = 66, D_out = 32, k = 3)   #32+32+2\n",
    "        self.disp2 = disp(D_in = 32, D_out = 2, k = 3, scale = 2)\n",
    "        #-------------------------------------------------------------#\n",
    "        self.upconv1 = upconv(D_in = 32, D_out = 16, k = 3, scale = 2) #h,w / 1\n",
    "        self.iconv1 = iconv(D_in = 18, D_out = 16, k = 3)\n",
    "        self.disp1 = disp(D_in = 16, D_out = 2, k = 3, scale = 2)\n",
    "        \n",
    "                \n",
    "    def forward(self,x):\n",
    "        \n",
    "        print('Encoder')\n",
    "        #encoder \n",
    "        x1 = self.conv1(x)  #conv1b\n",
    "        x2 = self.conv2(x1) #conv2b\n",
    "        x3 = self.conv3(x2) #conv3b\n",
    "        x4 = self.conv4(x3) #conv4b\n",
    "        x5 = self.conv5(x4) #conv5b \n",
    "        x6 = self.conv6(x5) #conv6b\n",
    "        x7 = self.conv7(x6) #conv7b\n",
    "        \n",
    "        encoder = [x1,x2,x3,x4,x5,x6,x7]\n",
    "        \n",
    "        for enc in encoder:\n",
    "            print(enc.size())\n",
    "        \n",
    "        \n",
    "        print ('Decoder')\n",
    "        #decoder \n",
    "        upconv7 = self.upconv7(x7)\n",
    "        iconv7 = self.iconv7(torch.cat((upconv7,x6),1))\n",
    "        \n",
    "        upconv6 = self.upconv6(iconv7)\n",
    "        iconv6 = self.iconv6(torch.cat((upconv6,x5),1))\n",
    "        \n",
    "        upconv5 = self.upconv5(iconv6)\n",
    "        iconv5 = self.iconv5(torch.cat((upconv5,x4),1))\n",
    "    \n",
    "        upconv4 = self.upconv4(iconv5)\n",
    "        iconv4 = self.iconv4(torch.cat((upconv4,x3),1))\n",
    "        self.disp4_out = self.disp4(iconv4)\n",
    "        self.udisp4 = torch.nn.functional.interpolate(self.disp4_out,scale_factor = 2, mode = 'bilinear',align_corners=True)\n",
    "        \n",
    "        upconv3 = self.upconv3(iconv4)\n",
    "        iconv3 = self.iconv3(torch.cat((upconv3,x2,self.udisp4),1))\n",
    "        self.disp3_out = self.disp3(iconv3)\n",
    "        self.udisp3 = torch.nn.functional.interpolate(self.disp3_out,scale_factor = 2, mode = 'bilinear',align_corners=True)\n",
    "        \n",
    "        upconv2 = self.upconv2(iconv3)\n",
    "        iconv2 = self.iconv2(torch.cat((upconv2,x1,self.udisp3),1))\n",
    "        self.disp2_out = self.disp2(iconv2)\n",
    "        self.udisp2 = torch.nn.functional.interpolate(self.disp2_out,scale_factor = 2, mode = 'bilinear',align_corners=True)\n",
    "        \n",
    "        upconv1 = self.upconv1(iconv2)\n",
    "        iconv1 = self.iconv1(torch.cat((upconv1,self.udisp2),1))\n",
    "        self.disp1_out = self.disp1(iconv1)\n",
    "        \n",
    "        decoder = [iconv7,iconv6,iconv5,iconv4,iconv3,iconv2,iconv1]\n",
    "        \n",
    "        for dec in decoder:\n",
    "            print(dec.size())\n",
    "         \n",
    "        return [self.disp1_out,self.disp2_out,self.disp3_out,self.disp4_out]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import MonodepthLoss\n",
    "from data_loader import prepare_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use a dataset with 29000 images\n"
     ]
    }
   ],
   "source": [
    "n_img, data_loader = prepare_dataloader(root_dir='../../data/kitti/', filenames_file = '../utils/filenames/kitti_train_files.txt' ,mode='train', batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Traceback (most recent call last):\n  File \"/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/Users/fabiankessler/Documents/01-Projects/Deep Learning in Computer Vision/project-dlcv/monodepth/data_loader.py\", line 40, in __getitem__\n    left_image = Image.open(self.left_paths[idx])\n  File \"/anaconda/lib/python3.6/site-packages/PIL/Image.py\", line 2477, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '../../data/kitti/2011_10_03/2011_10_03_drive_0034_sync/image_02/data/0000003007.jpg'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-161464a66c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = MonoDepthModel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left_image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Traceback (most recent call last):\n  File \"/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/Users/fabiankessler/Documents/01-Projects/Deep Learning in Computer Vision/project-dlcv/monodepth/data_loader.py\", line 40, in __getitem__\n    left_image = Image.open(self.left_paths[idx])\n  File \"/anaconda/lib/python3.6/site-packages/PIL/Image.py\", line 2477, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: '../../data/kitti/2011_10_03/2011_10_03_drive_0034_sync/image_02/data/0000003007.jpg'\n"
     ]
    }
   ],
   "source": [
    "#model = MonoDepthModel()\n",
    "image = next(iter(data_loader))['left_image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2, d3, d4 = model(image.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(d1.detach().cpu().numpy()[0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img, data_loader = prepare_dataloader('../../data/kitti/', '../../utils/filenames/' ,mode='train', batch_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
