{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from monodepth import MonodepthLoss\n",
    "from monodepth.data_loader import prepare_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv(nn.Module):\n",
    "    def __init__(self, num_in_layers, num_out_layers, kernel_size, stride):\n",
    "        super(conv, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv_base = nn.Conv2d(num_in_layers, num_out_layers, kernel_size=kernel_size, stride=stride)\n",
    "        self.normalize = nn.BatchNorm2d(num_out_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        p = int(np.floor((self.kernel_size-1)/2))\n",
    "        p2d = (p, p, p, p)\n",
    "        x = self.conv_base(F.pad(x, p2d))\n",
    "        x = self.normalize(x)\n",
    "        return F.elu(x, inplace=True)\n",
    "\n",
    "\n",
    "class convblock(nn.Module):\n",
    "    def __init__(self, num_in_layers, num_out_layers, kernel_size):\n",
    "        super(convblock, self).__init__()\n",
    "        self.conv1 = conv(num_in_layers, num_out_layers, kernel_size, 1)\n",
    "        self.conv2 = conv(num_out_layers, num_out_layers, kernel_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.conv2(x)\n",
    "\n",
    "\n",
    "class maxpool(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(maxpool, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        p = int(np.floor((self.kernel_size-1) / 2))\n",
    "        p2d = (p, p, p, p)\n",
    "        return F.max_pool2d(F.pad(x, p2d), self.kernel_size, stride=2)\n",
    "\n",
    "\n",
    "class resconv(nn.Module):\n",
    "    def __init__(self, num_in_layers, num_out_layers, stride):\n",
    "        super(resconv, self).__init__()\n",
    "        self.num_out_layers = num_out_layers\n",
    "        self.stride = stride\n",
    "        self.conv1 = conv(num_in_layers, num_out_layers, 1, 1)\n",
    "        self.conv2 = conv(num_out_layers, num_out_layers, 3, stride)\n",
    "        self.conv3 = nn.Conv2d(num_out_layers, 4*num_out_layers, kernel_size=1, stride=1)\n",
    "        self.conv4 = nn.Conv2d(num_in_layers, 4*num_out_layers, kernel_size=1, stride=stride)\n",
    "        self.normalize = nn.BatchNorm2d(4*num_out_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # do_proj = x.size()[1] != self.num_out_layers or self.stride == 2\n",
    "        do_proj = True\n",
    "        shortcut = []\n",
    "        x_out = self.conv1(x)\n",
    "        x_out = self.conv2(x_out)\n",
    "        x_out = self.conv3(x_out)\n",
    "        if do_proj:\n",
    "            shortcut = self.conv4(x)\n",
    "        else:\n",
    "            shortcut = x\n",
    "        return F.elu(self.normalize(x_out + shortcut), inplace=True)\n",
    "\n",
    "\n",
    "class resconv_basic(nn.Module):\n",
    "    # for resnet18\n",
    "    def __init__(self, num_in_layers, num_out_layers, stride):\n",
    "        super(resconv_basic, self).__init__()\n",
    "        self.num_out_layers = num_out_layers\n",
    "        self.stride = stride\n",
    "        self.conv1 = conv(num_in_layers, num_out_layers, 3, stride)\n",
    "        self.conv2 = conv(num_out_layers, num_out_layers, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(num_in_layers, num_out_layers, kernel_size=1, stride=stride)\n",
    "        self.normalize = nn.BatchNorm2d(num_out_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #         do_proj = x.size()[1] != self.num_out_layers or self.stride == 2\n",
    "        do_proj = True\n",
    "        shortcut = []\n",
    "        x_out = self.conv1(x)\n",
    "        x_out = self.conv2(x_out)\n",
    "        if do_proj:\n",
    "            shortcut = self.conv3(x)\n",
    "        else:\n",
    "            shortcut = x\n",
    "        return F.elu(self.normalize(x_out + shortcut), inplace=True)\n",
    "\n",
    "\n",
    "def resblock(num_in_layers, num_out_layers, num_blocks, stride):\n",
    "    layers = []\n",
    "    layers.append(resconv(num_in_layers, num_out_layers, stride))\n",
    "    for i in range(1, num_blocks - 1):\n",
    "        layers.append(resconv(4 * num_out_layers, num_out_layers, 1))\n",
    "    layers.append(resconv(4 * num_out_layers, num_out_layers, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def resblock_basic(num_in_layers, num_out_layers, num_blocks, stride):\n",
    "    layers = []\n",
    "    layers.append(resconv_basic(num_in_layers, num_out_layers, stride))\n",
    "    for i in range(1, num_blocks):\n",
    "        layers.append(resconv_basic(num_out_layers, num_out_layers, 1))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class upconv(nn.Module):\n",
    "    def __init__(self, num_in_layers, num_out_layers, kernel_size, scale):\n",
    "        super(upconv, self).__init__()\n",
    "        self.scale = scale\n",
    "        self.conv1 = conv(num_in_layers, num_out_layers, kernel_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.interpolate(x, scale_factor=self.scale, mode='bilinear', align_corners=True)\n",
    "        return self.conv1(x)\n",
    "\n",
    "\n",
    "class get_disp(nn.Module):\n",
    "    def __init__(self, num_in_layers):\n",
    "        super(get_disp, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_in_layers, 2, kernel_size=3, stride=1)\n",
    "        self.normalize = nn.BatchNorm2d(2)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        p = 1\n",
    "        p2d = (p, p, p, p)\n",
    "        x = self.conv1(F.pad(x, p2d))\n",
    "        x = self.normalize(x)\n",
    "        return 0.3 * self.sigmoid(x)\n",
    "\n",
    "\n",
    "class Resnet50_md(nn.Module):\n",
    "    def __init__(self, num_in_layers):\n",
    "        super(Resnet50_md, self).__init__()\n",
    "        # encoder\n",
    "        self.conv1 = conv(num_in_layers, 64, 7, 2)  # H/2  -   64D\n",
    "        self.pool1 = maxpool(3)  # H/4  -   64D\n",
    "        self.conv2 = resblock(64, 64, 3, 2)  # H/8  -  256D\n",
    "        self.conv3 = resblock(256, 128, 4, 2)  # H/16 -  512D\n",
    "        self.conv4 = resblock(512, 256, 6, 2)  # H/32 - 1024D\n",
    "        self.conv5 = resblock(1024, 512, 3, 2)  # H/64 - 2048D\n",
    "\n",
    "        # decoder\n",
    "        self.upconv6 = upconv(2048, 512, 3, 2)\n",
    "        self.iconv6 = conv(1024 + 512, 512, 3, 1)\n",
    "\n",
    "        self.upconv5 = upconv(512, 256, 3, 2)\n",
    "        self.iconv5 = conv(512+256, 256, 3, 1)\n",
    "\n",
    "        self.upconv4 = upconv(256, 128, 3, 2)\n",
    "        self.iconv4 = conv(256+128, 128, 3, 1)\n",
    "        self.disp4_layer = get_disp(128)\n",
    "\n",
    "        self.upconv3 = upconv(128, 64, 3, 2)\n",
    "        self.iconv3 = conv(64+64+2, 64, 3, 1)\n",
    "        self.disp3_layer = get_disp(64)\n",
    "\n",
    "        self.upconv2 = upconv(64, 32, 3, 2)\n",
    "        self.iconv2 = conv(32+64+2, 32, 3, 1)\n",
    "        self.disp2_layer = get_disp(32)\n",
    "\n",
    "        self.upconv1 = upconv(32, 16, 3, 2)\n",
    "        self.iconv1 = conv(16+2, 16, 3, 1)\n",
    "        self.disp1_layer = get_disp(16)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x1 = self.conv1(x)\n",
    "        x_pool1 = self.pool1(x1)\n",
    "        x2 = self.conv2(x_pool1)\n",
    "        x3 = self.conv3(x2)\n",
    "        x4 = self.conv4(x3)\n",
    "        x5 = self.conv5(x4)\n",
    "\n",
    "        # skips\n",
    "        skip1 = x1\n",
    "        skip2 = x_pool1\n",
    "        skip3 = x2\n",
    "        skip4 = x3\n",
    "        skip5 = x4\n",
    "\n",
    "        # decoder\n",
    "        upconv6 = self.upconv6(x5)\n",
    "        concat6 = torch.cat((upconv6, skip5), 1)\n",
    "        iconv6 = self.iconv6(concat6)\n",
    "\n",
    "        upconv5 = self.upconv5(iconv6)\n",
    "        concat5 = torch.cat((upconv5, skip4), 1)\n",
    "        iconv5 = self.iconv5(concat5)\n",
    "\n",
    "        upconv4 = self.upconv4(iconv5)\n",
    "        concat4 = torch.cat((upconv4, skip3), 1)\n",
    "        iconv4 = self.iconv4(concat4)\n",
    "        self.disp4 = self.disp4_layer(iconv4)\n",
    "        self.udisp4 = nn.functional.interpolate(self.disp4, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        upconv3 = self.upconv3(iconv4)\n",
    "        concat3 = torch.cat((upconv3, skip2, self.udisp4), 1)\n",
    "        iconv3 = self.iconv3(concat3)\n",
    "        self.disp3 = self.disp3_layer(iconv3)\n",
    "        self.udisp3 = nn.functional.interpolate(self.disp3, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        upconv2 = self.upconv2(iconv3)\n",
    "        concat2 = torch.cat((upconv2, skip1, self.udisp3), 1)\n",
    "        iconv2 = self.iconv2(concat2)\n",
    "        self.disp2 = self.disp2_layer(iconv2)\n",
    "        self.udisp2 = nn.functional.interpolate(self.disp2, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        upconv1 = self.upconv1(iconv2)\n",
    "        concat1 = torch.cat((upconv1, self.udisp2), 1)\n",
    "        iconv1 = self.iconv1(concat1)\n",
    "        self.disp1 = self.disp1_layer(iconv1)\n",
    "        return self.disp1, self.disp2, self.disp3, self.disp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use a dataset with 108 images\n"
     ]
    }
   ],
   "source": [
    "n_img, data_loader = prepare_dataloader('data/kitti', mode='train', batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "model = Resnet50_md(num_in_layers=3)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "md_loss = MonodepthLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    for batch in data_loader:\n",
    "        left, right = data['left_image'], data['right_image']\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        d1, d2, d3, d4 = model(left)\n",
    "        loss = md_loss((d1, d2, d3, d4), (left, right))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = next(iter(data_loader))\n",
    "left, right = data['left_image'], data['right_image']\n",
    "\n",
    "d1, d2, d3, d4 = model(left)\n",
    "plt.imshow(d1.detach().cpu().numpy()[0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left.detach().cpu().numpy()[0].transpose((1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Deep Learning)",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
