\documentclass[11pt,english]{article}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{authblk}
\usepackage{hyperref}

% Titel
\title{Proposal for Deep Learning in Computer Vision Practical Course}

\author{Fabian Kessler}
\author{Dominik Straub}
\author{Steven Lang}

\author{
	Straub, Dominik \texttt{dominikstraub@yahoo.com}
	\and
	Kessler, Fabian \texttt{fabiankessler1@gmail.com}
	\and
	Lang, Steven \texttt{steven.lang.mz@gmail.com}\\
}

\begin{document}

\maketitle
\section{Motivation}
Deep learning is a quickly evolving field that has already beaten many previous state-of-the-art results in machine learning tasks such as image classification, object detection, speech recognition, document classification and more. To understand deep learning it is not only necessary to learn the theoretical foundations and ideas but also to get hands on experience with novel architectures, software frameworks and datasets. Therefore, the \textit{Deep Learning in Computer Vision} practical course offers a perfect opportunity to gain firsthand experience and apply what we have learned so far. Furthermore, its focus on understanding deep networks instead of merely chasing benchmarks makes this course especially exciting, since robustness and reliability of computer vision applications will play an important role in future research and real-world scenarios.

\section{Prior Experience}
The following quickly summarizes our prior experience in the field of deep learning:

\paragraph{Dominik Straub}
\begin{itemize}
    \setlength\itemsep{-0.25em}
    \item Deep Learning: Architectures and Methods course (TU Darmstadt), including project on \textit{Sparse Autoencoders and Natural Image Statistics}
    \item Applied Cognitive Modeling course (TU Darmstadt): implement a version of Bayesian Conditional Density Estimation in PyTorch \footnote{\url{https://github.com/compercept/acm2017_abc}}
\end{itemize}
\paragraph{Fabian Kessler}
\begin{itemize}
    \setlength\itemsep{-0.25em}
    \item Stanford CS231n online lecture 
    \item Basic knowledge of PyTorch
    \item Basic background in machine learning (Statistical Machine Learning) and computer vision (CV1 and CV2) and bayesian methods (Applied Cognitive Modeling, Computational Foundations of Cognitive Science)
\end{itemize}
\paragraph{Steven Lang}
\begin{itemize}
	\setlength\itemsep{-0.25em}
	\item Deep Learning on Visual Data course (JGU Mainz), including practical project \textit{Deep Feature Interpolation} \cite{DBLP:journals/corr/UpchurchGBPSW16} implemented in TensorFlow \footnote{\url{https://github.com/steven-lang/dfi-tensorflow}}
	\item Integration of Deeplearning4j into the Weka software \footnote{\url{https://github.com/Waikato/wekaDeeplearning4j}}
\end{itemize}

\section{Favored Topics and Motivation}
\paragraph{Priority 1: Sample Free Bayesian SegNets} Although being crucial to interpretability and robustness of deep networks, Bayesian approaches are currently underinvestigated and are not included in classical deep learning introduction literature, which makes it a good topic to dive into. From a practical perspective it would be interesting to see how much this approach can be improved and whether it could become a feasible solution in real-world applications. 
\paragraph{Priority 2: Using Atrous convolutions for monocular depth estimation} This project seems like a great way to gain hands-on experience with modern convolutional architectures as well as an interesting approach to the challenging problem of depth estimation from single images. Additionally we would learn a lot about the practical design considerations with regards to memory-efficient performance, which is highly relevant for the widespread usage of this method.

\bibliographystyle{plain}
\bibliography{references}
\end{document}
